{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as sm\n",
    "import patsy\n",
    "import itertools\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_curve, roc_auc_score, auc\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, KFold, GridSearchCV,learning_curve\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, StratifiedShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB, GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer \n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/yesplum/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_extraction import stop_words\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from string import printable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../data_src/DS_27Mar2020a.csv', '../data_src/DS_27Mar2020b.csv', '../data_src/ML_27Mar2020b.csv', '../data_src/ML_27Mar2020a.csv', '../data_src/AI_26Mar2020.csv']\n"
     ]
    }
   ],
   "source": [
    "import glob, os\n",
    "\n",
    "extension = 'csv' \n",
    "src_path = '../data_src/'\n",
    "output_path = '../output/'\n",
    "\n",
    "all_filenames = [i for i in glob.glob('{}*.{}'.format(src_path,extension))] \n",
    "print(all_filenames)\n",
    "\n",
    "#combine all files in the list \n",
    "\n",
    "df_raw = pd.concat([pd.read_csv(f, encoding='unicode escape',skiprows=0) for f in all_filenames ]) \n",
    "df_raw.reset_index(inplace=True) \n",
    "df_raw = df_raw.drop(columns=['index','Unnamed: 0']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_clean(df):\n",
    "    \n",
    "    #remove duplicate based on Job ID\n",
    "    job_clean = df_raw.drop_duplicates(subset='Job_Id', keep='first')\n",
    "    #drop Salary_Type due to only one unique value 'Monthly'\n",
    "    job_clean = job_clean.drop(columns='Salary_Type')\n",
    "    #remove job without title\n",
    "    job_no_title = job_clean['Job_Title'] == ''\n",
    "    job_clean = job_clean[~job_no_title]\n",
    "    #remove row with all NaN value\n",
    "    job_clean[job_clean.isnull().any(axis=1)]\n",
    "    job_clean = job_clean.dropna()\n",
    "    \n",
    "    #perform data cleaning on every row and columms\n",
    "    clean_list = \"(\\[|\\]|b'|Requirements|'|amp;|xa0|\\\\\\|xe2x80x93|\\\\n|div class=|div class=|span class=|dib|lh-solid|/span|f5-5 i fw4 gray|f5 fw4 ph1|<|>|/div|\\\")\"\n",
    "    for col in job_clean.columns.difference(['Requirements']):\n",
    "        job_clean[col]=job_clean[col].str.replace(clean_list, \"\")\n",
    "\n",
    "    #space remain for Requirements column    \n",
    "    job_clean['Requirements']=job_clean['Requirements'].str.replace(clean_list, \" \")\n",
    "\n",
    "    #remove all non-ascii char except punctuation, digits, ascii_letters and whitespace\n",
    "    job_clean['Requirements'] = job_clean['Requirements'].apply(lambda y: ''.join(filter(lambda x: x in printable, y)))\n",
    "    \n",
    "    #further remove job with same data from all columns\n",
    "    job_clean = job_clean.drop_duplicates(subset=job_clean.columns, keep='first') \n",
    "        \n",
    "    #further filter on job title with specific keywords\n",
    "    title_key = ['DATA', 'MACHINE','ANALYST','MACHINE LEARNING','ANALYTICS', \"SCIENCE\", '4.0','APPLICATION'\n",
    "             'DEEP LEARNING','RESEARCH','NLP', 'ARTIFICIAL', \"INTELLIGENT\", 'AI', 'SCIENTIST','SYSTEM'\n",
    "             'Industry', 'IOT', 'FINANCE', 'FINTECH', 'SOFTWARE', 'ENGINEER', 'ENGINEERING','PROFESSOR'\n",
    "             'BUSINESS', 'DEVELOPER', 'INDUSTRIAL','AUTOMATION', 'CLOUD','SOLUTION','ARCHITECT',\n",
    "             'MANAGER','VP','PRESIDENT', 'TECHNOLOGY', 'SPECIALIST', 'TECHNICAL','LEAD','TECHNOLOGIST']\n",
    "    key = '|'.join(title_key)\n",
    "    data_job = job_clean['Job_Title'].str.upper().str.contains(key)\n",
    "    job_clean = job_clean[data_job]\n",
    "\n",
    "    #remove job title with unwanted keywords\n",
    "    title_key = ['PHYSIOTHERAPIST','ACCOUNT','AUDIT','COUNSEL','EXECUTIVE','SALES','GENERAL','MARKET',\n",
    "                 'ELECTRICAL','BUSINESS','ADMIN','CUSTOMER','OFFICER','OPERATION', 'MECHANICAL','CHEMICAL',\n",
    "                 'COORDINATOR','LECTURER','TECHNICIAN']\n",
    "    key = '|'.join(title_key)\n",
    "    non_data_job = job_clean['Job_Title'].str.upper().str.contains(key)\n",
    "    job_clean = job_clean[~non_data_job]\n",
    "    \n",
    "    #remove job with multiple category\n",
    "    cat_list = \"(/|and)\"\n",
    "    job_clean['Category']=job_clean['Category'].str.replace(cat_list, \",\")\n",
    "    job_clean['Cat_num'] = job_clean['Category'].str.count(',')\n",
    "    \n",
    "    multiple_cat = job_clean['Cat_num']>5\n",
    "    job_clean = job_clean[~multiple_cat]\n",
    "    job_clean = job_clean.drop(columns='Cat_num')\n",
    "    \n",
    "    #remove job with no or multiple seniority\n",
    "    senior_rule = (job_clean['Seniority'].str.count(',')>=1) | (job_clean['Seniority']=='')\n",
    "    job_clean = job_clean[~senior_rule]\n",
    "\n",
    "    \n",
    "    #remove job cat with specific keywords\n",
    "    rare_cat_key = ['HUMAN','SOCIAL','THERAPY','TAXATION','CUSTOMER','INTERIOR', 'ADMIN','BUILDING',\n",
    "                    'SECRETARIAL','INVESTIGATION', 'AUDITING', 'ENVIRONMENT','SALES', 'MARKETING',\n",
    "                    'ADVERTISING','CONSTRUCTION', 'DESIGN','LEGAL','HOSPITALITY','PROFESSIONAL']\n",
    "    key = '|'.join(rare_cat_key)\n",
    "    rare_cat = job_clean['Category'].str.upper().str.contains(key)\n",
    "    job_clean = job_clean[~rare_cat]\n",
    "    \n",
    "    #remove row without salary\n",
    "    no_salary = job_clean['Salary_Range'].str.contains('Salary undisclosed')\n",
    "    df_salary = job_clean[~no_salary]\n",
    "    df_no_salary = job_clean[no_salary]\n",
    "    df_salary = df_salary.reset_index(drop=True)\n",
    "    \n",
    "    req_empty = []\n",
    "\n",
    "    for i in range (len(df_salary)):\n",
    "    \n",
    "        if((len(df_salary['Requirements'][i]))<5):\n",
    "            req_empty.append(i)\n",
    "           \n",
    "    #clean & remove row without requirements\n",
    "    df_salary['Requirements']=df_salary['Requirements'].str.replace('(\\n)', \"\")\n",
    "    df_salary = df_salary.drop(req_empty)\n",
    "    df_salary = df_salary.reset_index(drop=True)\n",
    "\n",
    "    return df_salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(458, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data_clean(df_raw)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def salary_feature(df):\n",
    "    \n",
    "    #extract salary columns due to contain multiple information\n",
    "    salary_range = df[\"Salary_Range\"].str.split(\"to\", n = 2, expand = True) \n",
    "\n",
    "    #Give columns name to the dataframe\n",
    "    salary_range = salary_range.rename({0:'Min_Salary',1:'Max_Salary'}, axis='columns')\n",
    "\n",
    "    #removed $ and , from salary \n",
    "    for col in salary_range.columns:\n",
    "        salary_range[col]=salary_range[col].str.replace('(\\$|,)', '')\n",
    "\n",
    "    #convert from ojbect to float for statistical infomation\n",
    "    salary_range['Min_Salary'] = salary_range['Min_Salary'].astype('float64')\n",
    "    salary_range['Max_Salary'] = salary_range['Max_Salary'].astype('float64')\n",
    "    \n",
    "    #concat min_max salary dataframe with salary range dataframe\n",
    "    df_salary1 = pd.concat([df, salary_range], axis=1)\n",
    "    df_salary1 = df_salary1.drop(columns='Salary_Range')  \n",
    "    \n",
    "    #create a condition to check for high outliers\n",
    "    abovemean_min = round(10*np.mean(df_salary1['Min_Salary']),0)\n",
    "    abovemean_max = round(10*np.mean(df_salary1['Max_Salary']),0)\n",
    "    \n",
    "    #convert yearly salary into monthly salary\n",
    "\n",
    "    df_salary1['Min_Salary'] = np.where((df_salary1['Min_Salary'] > abovemean_min),\n",
    "                                    round((df_salary1['Min_Salary']/12),0), df_salary1['Min_Salary'])\n",
    "\n",
    "    df_salary1['Max_Salary'] = np.where((df_salary1['Max_Salary'] > abovemean_min),\n",
    "                                    round((df_salary1['Max_Salary']/12),0), df_salary1['Max_Salary'])\n",
    "    \n",
    "    #drop unrealistic min and max monthly salary range (which is more than 10 times)\n",
    "    min_max_abnormal = (df_salary1['Max_Salary']>10*df_salary1['Min_Salary'])\n",
    "    df_salary1 = df_salary1[~min_max_abnormal]\n",
    "    \n",
    "    #drop job with max salary less than 2500, assuming data entry/admin/operator job\n",
    "    low_sal = ((df_salary1['Min_Salary']<=1800) | (df_salary1['Max_Salary']<=2500))\n",
    "    df_salary1 = df_salary1[~low_sal]\n",
    "    \n",
    "    #create new feature for average salary\n",
    "    df_salary1['Avg_Salary'] = (df_salary1['Min_Salary'] + df_salary1['Max_Salary']) / 2\n",
    "    \n",
    "    #drop job with outlier salary\n",
    "    salary_outlier = ((df_salary1['Avg_Salary']>20000) | (df_salary1['Avg_Salary']<3000))\n",
    "    df_salary1 = df_salary1[~salary_outlier]\n",
    "    \n",
    "    #bin salary into 4 groups:\n",
    "    #3000 to 5500 - Low\n",
    "    #5500 to 8000 - Med\n",
    "    #8000 and above - High\n",
    "\n",
    "    bins = [3000, 4500, 6000, np.inf]\n",
    "    names = ['Low', 'Med', 'High']\n",
    "\n",
    "    df_salary1['Salary_range'] = pd.cut(df_salary1['Avg_Salary'], bins, labels=names)\n",
    "    df_salary1 = df_salary1.reset_index(drop=True)\n",
    "    \n",
    "    return df_salary1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(457, 13)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = salary_feature(df)\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emp_type(df):\n",
    "\n",
    "    \n",
    "    #remove others employment type\n",
    "    type_key = ['PART TIME','TEMPORARY','INTERNSHIP','FLEXI','FREELANCE']\n",
    "    key = '|'.join(type_key)\n",
    "    non_type = df['Emp_Type'].str.upper().str.contains(key)\n",
    "    df = df[~non_type]\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    #consolidate employment type\n",
    "    consolidate = \"(Full Time|Permanent, Full Time)\"\n",
    "    df['Emp_Type']=df['Emp_Type'].str.replace(consolidate, \"Permanent\")\n",
    "\n",
    "    consolidate = \"(Contract, Full Time)\"\n",
    "    df['Emp_Type']=df['Emp_Type'].str.replace(consolidate, \"Contract\")\n",
    "\n",
    "    consolidate = \"(Contract, Permanent, Full Time)\"\n",
    "    df['Emp_Type']=df['Emp_Type'].str.replace(consolidate, \"Cont_Perm\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(453, 13)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = emp_type(df1)\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seniority(df):\n",
    "    \n",
    "    #consolidate seniority from 9 groups to 4 groups\n",
    "    \n",
    "    df['Seniority'] = np.where((df['Seniority'] == 'Fresh/entry level') | (df['Seniority'] == 'Non-executive') | (df['Seniority'] == 'Junior Executive'),\n",
    "                                 'Jr Executive', df['Seniority'])\n",
    "    df['Seniority'] = np.where((df['Seniority'] == 'Executive') | (df['Seniority'] == 'Senior Executive'),\n",
    "                                 'Sr Executive', df['Seniority'])\n",
    "    df['Seniority'] = np.where((df['Seniority'] == 'Manager') | (df['Seniority'] == 'Middle Management') | (df['Seniority'] == 'Senior Management'),\n",
    "                                 'Management', df['Seniority'])   \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1 = seniority(df1)\n",
    "#df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_name(df):\n",
    "    \n",
    "    stacked = pd.DataFrame(df['Category'].str.split(',').tolist()).stack()\n",
    "    cat_count = pd.DataFrame(stacked.value_counts(), columns=['Count']).reset_index()\n",
    "    cat_count1 = []\n",
    "\n",
    "    for i in range (len(cat_count)):\n",
    "        cat_count1.append(cat_count['index'][i].lstrip())\n",
    "    \n",
    "    cat_name = list(dict.fromkeys(cat_count1))\n",
    "    return cat_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Laboratory ', 'R&D', 'Information Technology', 'Sciences ', 'Engineering', 'Finance', 'Banking ', 'Civil Service', 'Public ', 'Consulting', 'Telecommunications', 'Others', 'Manufacturing', 'Pharmaceutical', 'Healthcare ', 'Education ', 'Training', 'Insurance', 'General Management', 'Supply Chain', 'Logistics ', 'Risk Management']\n"
     ]
    }
   ],
   "source": [
    "print(cat_name(df1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_kie(df):\n",
    "\n",
    "    #extract only number from string\n",
    "    df['Year_Experience'] = df['Year_Experience'].str.extract('(\\d+)')\n",
    "    \n",
    "    #remove comma from cell with string\n",
    "    clean_list = \"(,|;|â||¦|®|)\"\n",
    "    for col in df.columns.difference(['Year_Experience','Min_Salary','Max_Salary','Avg_Salary']):\n",
    "        df[col]=df[col].str.replace(clean_list, \"\")\n",
    "        \n",
    "    #remove extra whitespace between string\n",
    "    df = df.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "    \n",
    "    #fill NaN in year of experience with 0\n",
    "    #df['Year_Experience'] = df['Year_Experience'].fillna(0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(453, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Id</th>\n",
       "      <th>Emp_Type</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Date_Posted</th>\n",
       "      <th>Year_Experience</th>\n",
       "      <th>Seniority</th>\n",
       "      <th>Category</th>\n",
       "      <th>Requirements</th>\n",
       "      <th>Min_Salary</th>\n",
       "      <th>Max_Salary</th>\n",
       "      <th>Avg_Salary</th>\n",
       "      <th>Salary_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MCF-2020-0045240</td>\n",
       "      <td>Contract Permanent</td>\n",
       "      <td>Scientist (Machine Intellection) I2R</td>\n",
       "      <td>A*STAR RESEARCH ENTITIES</td>\n",
       "      <td>Posted 27 Mar 2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Professional</td>\n",
       "      <td>Sciences  Laboratory  R&amp;D</td>\n",
       "      <td>Developing enhancing automating and managing a...</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MCF-2020-0045289</td>\n",
       "      <td>Contract Permanent</td>\n",
       "      <td>Scientist (Machine Intellection) I2R</td>\n",
       "      <td>A*STAR RESEARCH ENTITIES</td>\n",
       "      <td>Posted 27 Mar 2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Professional</td>\n",
       "      <td>Sciences  Laboratory  R&amp;D</td>\n",
       "      <td>Protein nodes discovering in cancer Biomarker ...</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Job_Id            Emp_Type                             Job_Title  \\\n",
       "0  MCF-2020-0045240  Contract Permanent  Scientist (Machine Intellection) I2R   \n",
       "1  MCF-2020-0045289  Contract Permanent  Scientist (Machine Intellection) I2R   \n",
       "\n",
       "                    Company         Date_Posted Year_Experience     Seniority  \\\n",
       "0  A*STAR RESEARCH ENTITIES  Posted 27 Mar 2020             NaN  Professional   \n",
       "1  A*STAR RESEARCH ENTITIES  Posted 27 Mar 2020             NaN  Professional   \n",
       "\n",
       "                    Category  \\\n",
       "0  Sciences  Laboratory  R&D   \n",
       "1  Sciences  Laboratory  R&D   \n",
       "\n",
       "                                        Requirements  Min_Salary  Max_Salary  \\\n",
       "0  Developing enhancing automating and managing a...      4500.0      9000.0   \n",
       "1  Protein nodes discovering in cancer Biomarker ...      4500.0      9000.0   \n",
       "\n",
       "   Avg_Salary Salary_range  \n",
       "0      6750.0         High  \n",
       "1      6750.0         High  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean = clean_kie(df1)\n",
    "print(df_clean.shape)\n",
    "df_clean.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def job_cat(df):\n",
    "    \n",
    "    cat_list = ['Information Technology', 'Telecommunications', 'Engineering','Sciences', 'Finance',\n",
    "                'Healthcare','Management','Consulting','Logistics', 'Civil', 'Others']\n",
    "    \n",
    "    for cat in cat_list:\n",
    "        df[cat] = np.where(df['Category'].str.contains(cat),1,0)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edu_cat(df):\n",
    "    \n",
    "    df['Requirements'] = df['Requirements'].str.lower()\n",
    "    \n",
    "    edu_list = ['phd','doctor','master','degree','computer science','engineering','statistic','math',\n",
    "               'computer engineering','business','ph.d']\n",
    "    \n",
    "    for edu in edu_list:\n",
    "        df[edu] = np.where(df['Requirements'].str.contains(edu),1,0)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skill_cat(df):\n",
    "    \n",
    "    df['Requirements'] = df['Requirements'].str.lower()\n",
    "    \n",
    "    skills_list = [ 'python','java','scala','hadoop','sql','spark','tensorflow','scikit','linux','pytorch','theano','caffe'\n",
    "                   ,'Matlab','perl','deep learning','nlp','apache','mapreduce','aws','azure','container','kafka','cassandra', 'c\\++'\n",
    "                   ,'julia','jupyter','nltk','tableau','power bi','sas','pandas','git','hive','impala','agile','machine learning','bash'\n",
    "                   ,'natural language','oracle','cloud','flask','golang','optimization','c#','opencv','computer vision','api','jira'\n",
    "                   ,'unix','bash','docker','keras', 'qlik','gcp','scrum', 'airflow','.net','d3.js'\n",
    "                  ]\n",
    "    \n",
    "    for skill in skills_list:\n",
    "        df[skill] = np.where(df['Requirements'].str.contains(skill),skill,0)\n",
    "    \n",
    "    return df, skills_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = job_cat(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean, skills_list = skill_cat(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skill_extract(df, skills_llist):\n",
    "    \n",
    "    sum_elements = [f\"df['{col}']\" for col in skills_list]\n",
    "    to_eval = \"+ '_' + \".join(sum_elements)\n",
    "    df['New_Skills'] = eval(to_eval)\n",
    "    clean_list = \"(0|_0|0_|_0_)\"\n",
    "    df['New_Skills']=df['New_Skills'].str.replace(clean_list, \"\")\n",
    "    df['New_Skills']=df['New_Skills'].str.replace('_', '%')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Id</th>\n",
       "      <th>Emp_Type</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Date_Posted</th>\n",
       "      <th>Year_Experience</th>\n",
       "      <th>Seniority</th>\n",
       "      <th>Category</th>\n",
       "      <th>Requirements</th>\n",
       "      <th>Min_Salary</th>\n",
       "      <th>...</th>\n",
       "      <th>unix</th>\n",
       "      <th>docker</th>\n",
       "      <th>keras</th>\n",
       "      <th>qlik</th>\n",
       "      <th>gcp</th>\n",
       "      <th>scrum</th>\n",
       "      <th>airflow</th>\n",
       "      <th>.net</th>\n",
       "      <th>d3.js</th>\n",
       "      <th>New_Skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MCF-2020-0045289</td>\n",
       "      <td>Contract Permanent</td>\n",
       "      <td>Scientist (Machine Intellection) I2R</td>\n",
       "      <td>A*STAR RESEARCH ENTITIES</td>\n",
       "      <td>Posted 27 Mar 2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Professional</td>\n",
       "      <td>Sciences  Laboratory  R&amp;D</td>\n",
       "      <td>protein nodes discovering in cancer biomarker ...</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>python%java%tensorflow%pytorch%theano%caffe%pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MCF-2020-0045282</td>\n",
       "      <td>Contract Permanent</td>\n",
       "      <td>Scientist (Machine Intellection) I2R</td>\n",
       "      <td>A*STAR RESEARCH ENTITIES</td>\n",
       "      <td>Posted 27 Mar 2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Professional</td>\n",
       "      <td>Sciences  Laboratory  R&amp;D</td>\n",
       "      <td>protein nodes discovering in cancer biomarker ...</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>python%java%tensorflow%pytorch%theano%caffe%pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MCF-2020-0072360</td>\n",
       "      <td>Contract Permanent</td>\n",
       "      <td>Senior Research Engineer (Computer Science)</td>\n",
       "      <td>NANYANG TECHNOLOGICAL UNIVERSITY</td>\n",
       "      <td>Posted 26 Mar 2020</td>\n",
       "      <td>5</td>\n",
       "      <td>Manager</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>data mining from massive data from documents t...</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>python%c\\++%machine learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MCF-2020-0072378</td>\n",
       "      <td>Contract Permanent</td>\n",
       "      <td>Research Engineer (Deep Learning 2.0) I2R</td>\n",
       "      <td>A*STAR RESEARCH ENTITIES</td>\n",
       "      <td>Posted 26 Mar 2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fresh/entry level</td>\n",
       "      <td>Sciences  Laboratory  R&amp;D</td>\n",
       "      <td>minimum bachelor in computer science statistic...</td>\n",
       "      <td>3900.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>python%java%theano%caffe%perl%deep learning%c\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MCF-2020-0071969</td>\n",
       "      <td>Contract Permanent</td>\n",
       "      <td>Senior Research Engineer (Computer Science)</td>\n",
       "      <td>NANYANG TECHNOLOGICAL UNIVERSITY</td>\n",
       "      <td>Posted 26 Mar 2020</td>\n",
       "      <td>5</td>\n",
       "      <td>Manager</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>design and implement natural language processi...</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>python%nlp%c\\++%natural language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>MCF-2020-0059189</td>\n",
       "      <td>Permanent</td>\n",
       "      <td>Software Engineer (Mapping /  localization)</td>\n",
       "      <td>ST ENGINEERING LAND SYSTEMS LTD.</td>\n",
       "      <td>Posted 10 Mar 2020</td>\n",
       "      <td>1</td>\n",
       "      <td>Professional</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>design and implement mapping localization and ...</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>%linux%c\\++%computer vision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>MCF-2020-0058649</td>\n",
       "      <td>Permanent</td>\n",
       "      <td>Senior Software Engineer (C++ / Python)</td>\n",
       "      <td>MANPOWER STAFFING SERVICES (SINGAPORE) PTE LTD</td>\n",
       "      <td>Posted 09 Mar 2020</td>\n",
       "      <td>5</td>\n",
       "      <td>Senior Executive</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>design real-time distributed applications for ...</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>python%sql%linux%c\\++%git%agile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>MCF-2020-0052725</td>\n",
       "      <td>Permanent</td>\n",
       "      <td>Systems Engineer</td>\n",
       "      <td>NUTONOMY ASIA PTE. LTD.</td>\n",
       "      <td>Posted 03 Mar 2020</td>\n",
       "      <td>4</td>\n",
       "      <td>Executive</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>define model and simulate the behavior of the ...</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>python%c\\++%computer vision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>MCF-2020-0050095</td>\n",
       "      <td>Permanent</td>\n",
       "      <td>DevOps Engineer</td>\n",
       "      <td>UCARE.IO PTE. LTD.</td>\n",
       "      <td>Posted 28 Feb 2020</td>\n",
       "      <td>2</td>\n",
       "      <td>Senior Executive</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>develop and lead the code deployment process. ...</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>python%java%perl%c\\++%git%cloud%c#%jira</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>MCF-2020-0049160</td>\n",
       "      <td>Contract Permanent</td>\n",
       "      <td>Research Engineer Social and Cognitive Computi...</td>\n",
       "      <td>A*STAR RESEARCH ENTITIES</td>\n",
       "      <td>Posted 27 Feb 2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fresh/entry level</td>\n",
       "      <td>Engineering Information Technology Sciences  L...</td>\n",
       "      <td>artificial intelligence systems  physics and c...</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>python%java%sql%c\\++%computer vision</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>131 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Job_Id            Emp_Type  \\\n",
       "1    MCF-2020-0045289  Contract Permanent   \n",
       "2    MCF-2020-0045282  Contract Permanent   \n",
       "5    MCF-2020-0072360  Contract Permanent   \n",
       "6    MCF-2020-0072378  Contract Permanent   \n",
       "7    MCF-2020-0071969  Contract Permanent   \n",
       "..                ...                 ...   \n",
       "438  MCF-2020-0059189           Permanent   \n",
       "440  MCF-2020-0058649           Permanent   \n",
       "444  MCF-2020-0052725           Permanent   \n",
       "446  MCF-2020-0050095           Permanent   \n",
       "450  MCF-2020-0049160  Contract Permanent   \n",
       "\n",
       "                                             Job_Title  \\\n",
       "1                 Scientist (Machine Intellection) I2R   \n",
       "2                 Scientist (Machine Intellection) I2R   \n",
       "5          Senior Research Engineer (Computer Science)   \n",
       "6            Research Engineer (Deep Learning 2.0) I2R   \n",
       "7          Senior Research Engineer (Computer Science)   \n",
       "..                                                 ...   \n",
       "438        Software Engineer (Mapping /  localization)   \n",
       "440            Senior Software Engineer (C++ / Python)   \n",
       "444                                   Systems Engineer   \n",
       "446                                    DevOps Engineer   \n",
       "450  Research Engineer Social and Cognitive Computi...   \n",
       "\n",
       "                                            Company         Date_Posted  \\\n",
       "1                          A*STAR RESEARCH ENTITIES  Posted 27 Mar 2020   \n",
       "2                          A*STAR RESEARCH ENTITIES  Posted 27 Mar 2020   \n",
       "5                  NANYANG TECHNOLOGICAL UNIVERSITY  Posted 26 Mar 2020   \n",
       "6                          A*STAR RESEARCH ENTITIES  Posted 26 Mar 2020   \n",
       "7                  NANYANG TECHNOLOGICAL UNIVERSITY  Posted 26 Mar 2020   \n",
       "..                                              ...                 ...   \n",
       "438                ST ENGINEERING LAND SYSTEMS LTD.  Posted 10 Mar 2020   \n",
       "440  MANPOWER STAFFING SERVICES (SINGAPORE) PTE LTD  Posted 09 Mar 2020   \n",
       "444                         NUTONOMY ASIA PTE. LTD.  Posted 03 Mar 2020   \n",
       "446                              UCARE.IO PTE. LTD.  Posted 28 Feb 2020   \n",
       "450                        A*STAR RESEARCH ENTITIES  Posted 27 Feb 2020   \n",
       "\n",
       "    Year_Experience          Seniority  \\\n",
       "1               NaN       Professional   \n",
       "2               NaN       Professional   \n",
       "5                 5            Manager   \n",
       "6               NaN  Fresh/entry level   \n",
       "7                 5            Manager   \n",
       "..              ...                ...   \n",
       "438               1       Professional   \n",
       "440               5   Senior Executive   \n",
       "444               4          Executive   \n",
       "446               2   Senior Executive   \n",
       "450             NaN  Fresh/entry level   \n",
       "\n",
       "                                              Category  \\\n",
       "1                            Sciences  Laboratory  R&D   \n",
       "2                            Sciences  Laboratory  R&D   \n",
       "5                               Information Technology   \n",
       "6                            Sciences  Laboratory  R&D   \n",
       "7                               Information Technology   \n",
       "..                                                 ...   \n",
       "438                             Information Technology   \n",
       "440                             Information Technology   \n",
       "444                             Information Technology   \n",
       "446                             Information Technology   \n",
       "450  Engineering Information Technology Sciences  L...   \n",
       "\n",
       "                                          Requirements  Min_Salary  ...  unix  \\\n",
       "1    protein nodes discovering in cancer biomarker ...      4500.0  ...     0   \n",
       "2    protein nodes discovering in cancer biomarker ...      4500.0  ...     0   \n",
       "5    data mining from massive data from documents t...      5500.0  ...     0   \n",
       "6    minimum bachelor in computer science statistic...      3900.0  ...     0   \n",
       "7    design and implement natural language processi...      5500.0  ...     0   \n",
       "..                                                 ...         ...  ...   ...   \n",
       "438  design and implement mapping localization and ...      4000.0  ...     0   \n",
       "440  design real-time distributed applications for ...      4000.0  ...     0   \n",
       "444  define model and simulate the behavior of the ...      7000.0  ...     0   \n",
       "446  develop and lead the code deployment process. ...      4000.0  ...     0   \n",
       "450  artificial intelligence systems  physics and c...      3000.0  ...     0   \n",
       "\n",
       "     docker keras  qlik  gcp  scrum  airflow  .net  d3.js  \\\n",
       "1         0     0     0    0      0        0     0      0   \n",
       "2         0     0     0    0      0        0     0      0   \n",
       "5         0     0     0    0      0        0     0      0   \n",
       "6         0     0     0    0      0        0     0      0   \n",
       "7         0     0     0    0      0        0     0      0   \n",
       "..      ...   ...   ...  ...    ...      ...   ...    ...   \n",
       "438       0     0     0    0      0        0     0      0   \n",
       "440       0     0     0    0      0        0     0      0   \n",
       "444       0     0     0    0      0        0     0      0   \n",
       "446       0     0     0    0      0        0     0      0   \n",
       "450       0     0     0    0      0        0     0      0   \n",
       "\n",
       "                                            New_Skills  \n",
       "1    python%java%tensorflow%pytorch%theano%caffe%pe...  \n",
       "2    python%java%tensorflow%pytorch%theano%caffe%pe...  \n",
       "5                         python%c\\++%machine learning  \n",
       "6    python%java%theano%caffe%perl%deep learning%c\\...  \n",
       "7                     python%nlp%c\\++%natural language  \n",
       "..                                                 ...  \n",
       "438                        %linux%c\\++%computer vision  \n",
       "440                    python%sql%linux%c\\++%git%agile  \n",
       "444                        python%c\\++%computer vision  \n",
       "446            python%java%perl%c\\++%git%cloud%c#%jira  \n",
       "450               python%java%sql%c\\++%computer vision  \n",
       "\n",
       "[131 rows x 82 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = skill_extract(df_clean, skills_list) # 504 ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word count function\n",
    "def word_count(df_col):\n",
    "\n",
    "    str_counts = 0\n",
    "    sum_str = 0\n",
    "\n",
    "    for i in range (len(df_col)):    \n",
    "        str_counts = len(df_col[i].split())\n",
    "        sum_str = sum_str + str_counts\n",
    "\n",
    "    print(sum_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78225\n"
     ]
    }
   ],
   "source": [
    "#number of word found in Requirements column before clean\n",
    "word_count(df_clean['Requirements'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_words(word_count, features):\n",
    "\n",
    "    num_word = np.asarray(word_count.sum(axis=0)).reshape(-1)\n",
    "    most_count = num_word.argsort()[::-1]\n",
    "    key_word = pd.Series(num_word[most_count], \n",
    "                           index=features[most_count])\n",
    "\n",
    "    return key_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_word_fil(df):\n",
    "    \n",
    "    #stop words were added to filter some generic recurring business terms.\n",
    "    stop = stopwords.words('english')\n",
    "    stop += ['regret','shortlisted', 'candidates','notified','etc', 'take', 'hands','added','able','writting',\n",
    "             'year','years','least', 'related','using', 'and', 'ability','work','skills','advantage','written'\n",
    "            'develop','good','team','design','knowledge','experience','following','areas', 'ability','and','in','to']\n",
    "    \n",
    "    #most common words for requirements\n",
    "    cvt = CountVectorizer(lowercase=True, strip_accents='unicode',max_features=80000, min_df=1, max_df=0.9,\n",
    "                          stop_words=stop, ngram_range=(1,2))\n",
    "    vect_word = cvt.fit_transform(df['Requirements'])\n",
    "    features = np.array(cvt.get_feature_names()) \n",
    "\n",
    "    key_word = freq_words(vect_word, features)\n",
    "    \n",
    "    #update stop_word with common words\n",
    "    new_stop = key_word[key_word<5].index\n",
    "    stop.extend(new_stop)\n",
    "    \n",
    "    pat = r'\\b(?:{})\\b'.format('|'.join(stop))\n",
    "    df['Requirements'] = df['Requirements'].str.replace(pat, \" \")\n",
    "    df['Requirements'] = df['Requirements'].map(lambda x: x.strip())\n",
    "    df['Requirements'] = df['Requirements'].replace({' +':\" \"},regex=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78225\n"
     ]
    }
   ],
   "source": [
    "#data_df = stop_word_fil(df_clean)\n",
    "data_df = df_clean.copy()\n",
    "#number of word found in Requirements column after clean\n",
    "word_count(data_df['Requirements'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(453, 82)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(453, 25)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = data_df.drop(columns=data_df[skills_list].columns)\n",
    "data_df['New_Skills'] = data_df['New_Skills'].str.replace(\"\\\\\", \"\")\n",
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save output file skills_list\n",
    "\n",
    "data_df.to_csv('{}JOB_DATA_v14.csv'.format(output_path), index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(352, 71)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = data_df.dropna(subset=['Year_Experience']).reset_index(drop=True)\n",
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(352, 83)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dummified Seniority columns to use as predictor features\n",
    "seniority_cat=data_df['Seniority'].str.get_dummies()\n",
    "emp_cat=data_df['Emp_Type'].str.get_dummies()\n",
    "df = pd.concat([data_df, seniority_cat, emp_cat], axis=1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=0.6, max_features=500, min_df=10,\n",
       "                ngram_range=(1, 2), preprocessor=None,\n",
       "                stop_words=['i', 'me', 'my', 'myself', 'we', 'our', 'ours',\n",
       "                            'ourselves', 'you', \"you're\", \"you've\", \"you'll\",\n",
       "                            \"you'd\", 'your', 'yours', 'yourself', 'yourselves',\n",
       "                            'he', 'him', 'his', 'himself', 'she', \"she's\",\n",
       "                            'her', 'hers', 'herself', 'it', \"it's\", 'its',\n",
       "                            'itself', ...],\n",
       "                strip_accents='unicode', token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CountVectorizer job requirements columns\n",
    "#min_df=10, max_df=0.6, max_features=500, ngram_range=(1,2), f1 = 0.61\n",
    "stop_ml = stopwords.words('english')\n",
    "\n",
    "stop_ml += ['possess','work','back','ability','communication', 'participate', 'like', 'tools','distributed',\n",
    "            'contribute','proven','engage','understanding','excellent', 'teams','experienced', 'familiarity',\n",
    "            'partners', 'study', 'well','preferably','user','field','experience','english', 'level','sets',\n",
    "            'delivery','implementation','relevant','state','exposure','record','problems','define','open',\n",
    "            'proficient','understand']\n",
    "\n",
    "cvec = CountVectorizer(lowercase=True, strip_accents='unicode',\n",
    "                       max_features=500, min_df=10, max_df=0.6, \n",
    "                       stop_words=stop_ml,ngram_range=(1,2))\n",
    "cvec.fit(df['Requirements'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating predictor and target dataset\n",
    "model_data = df.drop(columns=['Job_Title','Company','Seniority','Category','Min_Salary',\n",
    "                               'Max_Salary','Emp_Type','Avg_Salary', 'Job_Id', 'Date_Posted'])\n",
    "\n",
    "nlp = pd.DataFrame(cvec.transform(model_data['Requirements']).todense(),columns=cvec.get_feature_names())\n",
    "\n",
    "senior_nlp = pd.concat([model_data, nlp], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(352, 71)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = model_data.drop(columns=['Salary_range','Requirements'])\n",
    "X_nlp = senior_nlp.drop(columns=['Salary_range','Requirements'])\n",
    "y = senior_nlp['Salary_range'].values\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data with dummified 'seniority' and countvectorized 'requirements'\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data with countvectorized 'requirements' only\n",
    "X_train_nlp, X_test_nlp, y_train_nlp, y_test_nlp = train_test_split(X_nlp, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier(max_depth=4, random_state=42)\n",
    "dtc = dtc.fit(X_train , y_train)\n",
    "\n",
    "dtc1 = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "dtc_nlp = dtc1.fit(X_nlp , y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Low       0.83      0.70      0.76        69\n",
      "         Med       0.33      0.18      0.24        11\n",
      "        High       0.43      0.69      0.53        26\n",
      "\n",
      "    accuracy                           0.64       106\n",
      "   macro avg       0.53      0.52      0.51       106\n",
      "weighted avg       0.68      0.64      0.65       106\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,dtc.predict(X_test),target_names=[\"Low\", \"Med\", \"High\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred Low</th>\n",
       "      <th>Pred Med</th>\n",
       "      <th>Pred High</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Low</th>\n",
       "      <td>48</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Med</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual High</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Pred Low  Pred Med  Pred High\n",
       "Actual Low         48         4         17\n",
       "Actual Med          2         2          7\n",
       "Actual High         8         0         18"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(y_test,dtc.predict(X_test)),\n",
    "             index=['Actual Low','Actual Med', 'Actual High'],\n",
    "             columns=['Pred Low','Pred Med','Pred High'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Low       0.93      0.82      0.87       226\n",
      "         Med       0.65      0.70      0.68        37\n",
      "        High       0.58      0.73      0.64        89\n",
      "\n",
      "    accuracy                           0.78       352\n",
      "   macro avg       0.72      0.75      0.73       352\n",
      "weighted avg       0.81      0.78      0.79       352\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y,dtc_nlp.predict(X_nlp),target_names=[\"Low\", \"Med\", \"High\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred Low</th>\n",
       "      <th>Pred Med</th>\n",
       "      <th>Pred High</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Low</th>\n",
       "      <td>185</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Med</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual High</th>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Pred Low  Pred Med  Pred High\n",
       "Actual Low        185         3         38\n",
       "Actual Med          1        26         10\n",
       "Actual High        13        11         65"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(y,dtc_nlp.predict(X_nlp)),\n",
    "             index=['Actual Low','Actual Med', 'Actual High'],\n",
    "             columns=['Pred Low','Pred Med','Pred High'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>abs coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Year_Experience</th>\n",
       "      <td>0.405679</td>\n",
       "      <td>0.405679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sciences</th>\n",
       "      <td>0.098422</td>\n",
       "      <td>0.098422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>java scala</th>\n",
       "      <td>0.083142</td>\n",
       "      <td>0.083142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Non-executive</th>\n",
       "      <td>0.066195</td>\n",
       "      <td>0.066195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phd</th>\n",
       "      <td>0.061634</td>\n",
       "      <td>0.061634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>python java</th>\n",
       "      <td>0.046882</td>\n",
       "      <td>0.046882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>algorithms</th>\n",
       "      <td>0.043642</td>\n",
       "      <td>0.043642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>science engineering</th>\n",
       "      <td>0.043628</td>\n",
       "      <td>0.043628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opencv</th>\n",
       "      <td>0.037369</td>\n",
       "      <td>0.037369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>science computer</th>\n",
       "      <td>0.033332</td>\n",
       "      <td>0.033332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>software</th>\n",
       "      <td>0.030956</td>\n",
       "      <td>0.030956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Junior Executive</th>\n",
       "      <td>0.026203</td>\n",
       "      <td>0.026203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.018749</td>\n",
       "      <td>0.018749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variety</th>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.004167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>platforms</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         coef  abs coef\n",
       "Year_Experience      0.405679  0.405679\n",
       "Sciences             0.098422  0.098422\n",
       "java scala           0.083142  0.083142\n",
       "Non-executive        0.066195  0.066195\n",
       "phd                  0.061634  0.061634\n",
       "python java          0.046882  0.046882\n",
       "algorithms           0.043642  0.043642\n",
       "science engineering  0.043628  0.043628\n",
       "opencv               0.037369  0.037369\n",
       "science computer     0.033332  0.033332\n",
       "software             0.030956  0.030956\n",
       "Junior Executive     0.026203  0.026203\n",
       "test                 0.018749  0.018749\n",
       "variety              0.004167  0.004167\n",
       "platforms            0.000000  0.000000"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = np.array(X_nlp.columns)\n",
    "dt_coefs = pd.DataFrame({'coef':dtc_nlp.feature_importances_, 'abs coef':abs(dtc_nlp.feature_importances_)},index=features)\n",
    "dt_coefs = dt_coefs.sort_values('coef',ascending=False)\n",
    "dt_coefs.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree.export import export_text\n",
    "\n",
    "tree_rules = export_text(dtc, feature_names=list(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "#clf = tree.DecisionTreeClassifier(max_leaf_nodes=n)\n",
    "#clf_ = clf.fit(X, data_y)\n",
    "\n",
    "feature_names = X_nlp.columns\n",
    "class_name = dtc_nlp.classes_.astype(str)\n",
    "\n",
    "def output_pdf(model):\n",
    "    from sklearn import tree\n",
    "    from sklearn.externals.six import StringIO\n",
    "    import pydot_ng as pydot\n",
    "    dot_data = StringIO()\n",
    "    tree.export_graphviz(model, out_file=dot_data,\n",
    "                         feature_names=feature_names,\n",
    "                         class_names=class_name,\n",
    "                         filled=True, rounded=True,\n",
    "                         special_characters=True,\n",
    "                          node_ids=1,)\n",
    "    graph = pydot.graph_from_dot_data(dot_data.getvalue())\n",
    "    graph.write_pdf(\"{}DT.pdf\".format(output_path))\n",
    "\n",
    "output_pdf(dtc_nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
