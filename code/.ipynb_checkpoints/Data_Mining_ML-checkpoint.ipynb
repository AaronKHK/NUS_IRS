{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as sm\n",
    "import patsy\n",
    "import itertools\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_curve, roc_auc_score, auc\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, KFold, GridSearchCV,learning_curve\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, StratifiedShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB, GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer \n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/yesplum/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_extraction import stop_words\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../data_src/DS_27Mar2020a.csv', '../data_src/DS_27Mar2020b.csv', '../data_src/ML_27Mar2020b.csv', '../data_src/ML_27Mar2020a.csv', '../data_src/AI_26Mar2020.csv']\n"
     ]
    }
   ],
   "source": [
    "import glob, os\n",
    "\n",
    "extension = 'csv' \n",
    "src_path = '../data_src/'\n",
    "output_path = '../output/'\n",
    "\n",
    "all_filenames = [i for i in glob.glob('{}*.{}'.format(src_path,extension))] \n",
    "print(all_filenames)\n",
    "\n",
    "#combine all files in the list \n",
    "\n",
    "df_raw = pd.concat([pd.read_csv(f, encoding='unicode escape',skiprows=0) for f in all_filenames ]) \n",
    "df_raw.reset_index(inplace=True) \n",
    "df_raw = df_raw.drop(columns=['index','Unnamed: 0']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_clean(df):\n",
    "    \n",
    "    #remove duplicate based on Job ID\n",
    "    job_clean = df_raw.drop_duplicates(subset='Job_Id', keep='first')\n",
    "    #drop Salary_Type due to only one unique value 'Monthly'\n",
    "    job_clean = job_clean.drop(columns='Salary_Type')\n",
    "    #remove job without title\n",
    "    job_no_title = job_clean['Job_Title'] == ''\n",
    "    job_clean = job_clean[~job_no_title]\n",
    "    #remove row with all NaN value\n",
    "    job_clean[job_clean.isnull().any(axis=1)]\n",
    "    job_clean = job_clean.dropna()\n",
    "    \n",
    "    #perform data cleaning on every row and columms\n",
    "    clean_list = \"(\\[|\\]|b'|Requirements|'|amp;|xa0|\\\\\\|xe2x80x93|\\\\n|div class=|div class=|span class=|dib|lh-solid|/span|f5-5 i fw4 gray|f5 fw4 ph1|<|>|/div|\\\")\"\n",
    "    for col in job_clean.columns.difference(['Requirements']):\n",
    "        job_clean[col]=job_clean[col].str.replace(clean_list, \"\")\n",
    "\n",
    "    #space remain for Requirements column    \n",
    "    job_clean['Requirements']=job_clean['Requirements'].str.replace(clean_list, \" \")\n",
    "\n",
    "    clean_list2 = \"(Ã¢Â€Â|Ã¢Â€Âœ|Ã¢Â€Â™|ïƒ¼ Â|ïƒ¨|ïƒ¼|Â Â Â Â Â|Â|â€“|â€™|â€œâ€|Â|Ã¢Â€Â™️)\"\n",
    "    job_clean['Requirements']=job_clean['Requirements'].str.replace(clean_list2, \"\")\n",
    "    \n",
    "    #further remove job with same data from all columns\n",
    "    job_clean = job_clean.drop_duplicates(subset=job_clean.columns, keep='first') \n",
    "    \n",
    "    \n",
    "    #further filter on job title with specific keywords\n",
    "    title_key = ['DATA', 'MACHINE','ANALYST','MACHINE LEARNING','ANALYTICS', \"SCIENCE\", '4.0','APPLICATION'\n",
    "             'DEEP LEARNING','RESEARCH','NLP', 'ARTIFICIAL', \"INTELLIGENT\", 'AI', 'SCIENTIST','SYSTEM'\n",
    "             'Industry', 'IOT', 'FINANCE', 'FINTECH', 'SOFTWARE', 'ENGINEER', 'ENGINEERING','PROFESSOR'\n",
    "             'BUSINESS', 'DEVELOPER', 'INDUSTRIAL','AUTOMATION', 'CLOUD','SOLUTION','ARCHITECT',\n",
    "             'MANAGER','VP','PRESIDENT', 'TECHNOLOGY', 'SPECIALIST', 'TECHNICAL','LEAD','TECHNOLOGIST']\n",
    "    key = '|'.join(title_key)\n",
    "    data_job = job_clean['Job_Title'].str.upper().str.contains(key)\n",
    "    job_clean = job_clean[data_job]\n",
    "\n",
    "    #remove job title with unwanted keywords\n",
    "    title_key = ['PHYSIOTHERAPIST','ACCOUNT','AUDIT','COUNSEL','EXECUTIVE','SALES','GENERAL','MARKET',\n",
    "                 'ELECTRICAL','BUSINESS','ADMIN','CUSTOMER','OFFICER','OPERATION', 'MECHANICAL','CHEMICAL',\n",
    "                 'COORDINATOR','LECTURER','TECHNICIAN']\n",
    "    key = '|'.join(title_key)\n",
    "    non_data_job = job_clean['Job_Title'].str.upper().str.contains(key)\n",
    "    job_clean = job_clean[~non_data_job]\n",
    "    \n",
    "    #remove job with multiple category\n",
    "    cat_list = \"(/|and)\"\n",
    "    job_clean['Category']=job_clean['Category'].str.replace(cat_list, \",\")\n",
    "    job_clean['Cat_num'] = job_clean['Category'].str.count(',')\n",
    "    \n",
    "    multiple_cat = job_clean['Cat_num']>5\n",
    "    job_clean = job_clean[~multiple_cat]\n",
    "    job_clean = job_clean.drop(columns='Cat_num')\n",
    "    \n",
    "    #remove job with no or multiple seniority\n",
    "    senior_rule = (job_clean['Seniority'].str.count(',')>=1) | (job_clean['Seniority']=='')\n",
    "    job_clean = job_clean[~senior_rule]\n",
    "\n",
    "    \n",
    "    #remove job cat with specific keywords\n",
    "    rare_cat_key = ['HUMAN','SOCIAL','THERAPY','TAXATION','CUSTOMER','INTERIOR', 'ADMIN','BUILDING',\n",
    "                    'SECRETARIAL','INVESTIGATION', 'AUDITING', 'ENVIRONMENT','SALES', 'MARKETING',\n",
    "                    'ADVERTISING','CONSTRUCTION', 'DESIGN','LEGAL','HOSPITALITY','PROFESSIONAL']\n",
    "    key = '|'.join(rare_cat_key)\n",
    "    rare_cat = job_clean['Category'].str.upper().str.contains(key)\n",
    "    job_clean = job_clean[~rare_cat]\n",
    "    \n",
    "    #remove row without salary\n",
    "    no_salary = job_clean['Salary_Range'].str.contains('Salary undisclosed')\n",
    "    df_salary = job_clean[~no_salary]\n",
    "    df_no_salary = job_clean[no_salary]\n",
    "    df_salary = df_salary.reset_index(drop=True)\n",
    "    \n",
    "    req_empty = []\n",
    "\n",
    "    for i in range (len(df_salary)):\n",
    "    \n",
    "        if((len(df_salary['Requirements'][i]))<5):\n",
    "            req_empty.append(i)\n",
    "           \n",
    "    #clean & remove row without requirements\n",
    "    df_salary['Requirements']=df_salary['Requirements'].str.replace('(\\n)', \"\")\n",
    "    df_salary = df_salary.drop(req_empty)\n",
    "    df_salary = df_salary.reset_index(drop=True)\n",
    "\n",
    "    return df_salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(458, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data_clean(df_raw)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def salary_feature(df):\n",
    "    \n",
    "    #extract salary columns due to contain multiple information\n",
    "    salary_range = df[\"Salary_Range\"].str.split(\"to\", n = 2, expand = True) \n",
    "\n",
    "    #Give columns name to the dataframe\n",
    "    salary_range = salary_range.rename({0:'Min_Salary',1:'Max_Salary'}, axis='columns')\n",
    "\n",
    "    #removed $ and , from salary \n",
    "    for col in salary_range.columns:\n",
    "        salary_range[col]=salary_range[col].str.replace('(\\$|,)', '')\n",
    "\n",
    "    #convert from ojbect to float for statistical infomation\n",
    "    salary_range['Min_Salary'] = salary_range['Min_Salary'].astype('float64')\n",
    "    salary_range['Max_Salary'] = salary_range['Max_Salary'].astype('float64')\n",
    "    \n",
    "    #concat min_max salary dataframe with salary range dataframe\n",
    "    df_salary1 = pd.concat([df, salary_range], axis=1)\n",
    "    df_salary1 = df_salary1.drop(columns='Salary_Range')  \n",
    "    \n",
    "    #create a condition to check for high outliers\n",
    "    abovemean_min = round(10*np.mean(df_salary1['Min_Salary']),0)\n",
    "    abovemean_max = round(10*np.mean(df_salary1['Max_Salary']),0)\n",
    "    \n",
    "    #convert yearly salary into monthly salary\n",
    "\n",
    "    df_salary1['Min_Salary'] = np.where((df_salary1['Min_Salary'] > abovemean_min),\n",
    "                                    round((df_salary1['Min_Salary']/12),0), df_salary1['Min_Salary'])\n",
    "\n",
    "    df_salary1['Max_Salary'] = np.where((df_salary1['Max_Salary'] > abovemean_min),\n",
    "                                    round((df_salary1['Max_Salary']/12),0), df_salary1['Max_Salary'])\n",
    "    \n",
    "    #drop unrealistic min and max monthly salary range (which is more than 10 times)\n",
    "    min_max_abnormal = (df_salary1['Max_Salary']>10*df_salary1['Min_Salary'])\n",
    "    df_salary1 = df_salary1[~min_max_abnormal]\n",
    "    \n",
    "    #drop job with max salary less than 2500, assuming data entry/admin/operator job\n",
    "    low_sal = ((df_salary1['Min_Salary']<=1800) | (df_salary1['Max_Salary']<=2500))\n",
    "    df_salary1 = df_salary1[~low_sal]\n",
    "    \n",
    "    #create new feature for average salary\n",
    "    df_salary1['Avg_Salary'] = (df_salary1['Min_Salary'] + df_salary1['Max_Salary']) / 2\n",
    "    \n",
    "    #drop job with outlier salary\n",
    "    salary_outlier = ((df_salary1['Avg_Salary']>20000) | (df_salary1['Avg_Salary']<3000))\n",
    "    df_salary1 = df_salary1[~salary_outlier]\n",
    "    \n",
    "    #bin salary into 4 groups:\n",
    "    #3000 to 5500 - Low\n",
    "    #5500 to 8000 - Med\n",
    "    #8000 and above - High\n",
    "\n",
    "    bins = [3000, 5500, 8000, np.inf]\n",
    "    names = ['Low', 'Med', 'High']\n",
    "\n",
    "    df_salary1['Salary_range'] = pd.cut(df_salary1['Avg_Salary'], bins, labels=names)\n",
    "    df_salary1 = df_salary1.reset_index(drop=True)\n",
    "    \n",
    "    return df_salary1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(457, 13)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = salary_feature(df)\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emp_type(df):\n",
    "\n",
    "    \n",
    "    #remove others employment type\n",
    "    type_key = ['PART TIME','TEMPORARY','INTERNSHIP','FLEXI','FREELANCE']\n",
    "    key = '|'.join(type_key)\n",
    "    non_type = df['Emp_Type'].str.upper().str.contains(key)\n",
    "    df = df[~non_type]\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    #consolidate employment type\n",
    "    consolidate = \"(Full Time|Permanent, Full Time)\"\n",
    "    df['Emp_Type']=df['Emp_Type'].str.replace(consolidate, \"Permanent\")\n",
    "\n",
    "    consolidate = \"(Contract, Full Time)\"\n",
    "    df['Emp_Type']=df['Emp_Type'].str.replace(consolidate, \"Contract\")\n",
    "\n",
    "    consolidate = \"(Contract, Permanent, Full Time)\"\n",
    "    df['Emp_Type']=df['Emp_Type'].str.replace(consolidate, \"Cont_Perm\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(453, 13)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = emp_type(df1)\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seniority(df):\n",
    "    \n",
    "    #consolidate seniority from 9 groups to 4 groups\n",
    "    \n",
    "    df['Seniority'] = np.where((df['Seniority'] == 'Fresh/entry level') | (df['Seniority'] == 'Non-executive') | (df['Seniority'] == 'Junior Executive'),\n",
    "                                 'Jr Executive', df['Seniority'])\n",
    "    df['Seniority'] = np.where((df['Seniority'] == 'Executive') | (df['Seniority'] == 'Senior Executive'),\n",
    "                                 'Sr Executive', df['Seniority'])\n",
    "    df['Seniority'] = np.where((df['Seniority'] == 'Manager') | (df['Seniority'] == 'Middle Management') | (df['Seniority'] == 'Senior Management'),\n",
    "                                 'Management', df['Seniority'])   \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(453, 13)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = seniority(df1)\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_name(df):\n",
    "    \n",
    "    stacked = pd.DataFrame(df['Category'].str.split(',').tolist()).stack()\n",
    "    cat_count = pd.DataFrame(stacked.value_counts(), columns=['Count']).reset_index()\n",
    "    cat_count1 = []\n",
    "\n",
    "    for i in range (len(cat_count)):\n",
    "        cat_count1.append(cat_count['index'][i].lstrip())\n",
    "    \n",
    "    cat_name = list(dict.fromkeys(cat_count1))\n",
    "    return cat_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['R&D', 'Laboratory ', 'Information Technology', 'Sciences ', 'Engineering', 'Finance', 'Banking ', 'Civil Service', 'Consulting', 'Public ', 'Telecommunications', 'Others', 'Manufacturing', 'Healthcare ', 'Pharmaceutical', 'Education ', 'Training', 'Insurance', 'General Management', 'Logistics ', 'Risk Management', 'Supply Chain']\n"
     ]
    }
   ],
   "source": [
    "print(cat_name(df1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_kie(df):\n",
    "\n",
    "    #extract only number from string\n",
    "    df['Year_Experience'] = df['Year_Experience'].str.extract('(\\d+)')\n",
    "    \n",
    "    #remove comma from cell with string\n",
    "    clean_list = \"(,|;|â||¦|®|)\"\n",
    "    for col in df.columns.difference(['Year_Experience','Min_Salary','Max_Salary','Avg_Salary']):\n",
    "        df[col]=df[col].str.replace(clean_list, \"\")\n",
    "        \n",
    "    #remove extra whitespace between string\n",
    "    df = df.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "    \n",
    "    #fill NaN in year of experience with 0\n",
    "    df['Year_Experience'] = df['Year_Experience'].fillna(0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(453, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Id</th>\n",
       "      <th>Emp_Type</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Date_Posted</th>\n",
       "      <th>Year_Experience</th>\n",
       "      <th>Seniority</th>\n",
       "      <th>Category</th>\n",
       "      <th>Requirements</th>\n",
       "      <th>Min_Salary</th>\n",
       "      <th>Max_Salary</th>\n",
       "      <th>Avg_Salary</th>\n",
       "      <th>Salary_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MCF-2020-0045240</td>\n",
       "      <td>Contract Permanent</td>\n",
       "      <td>Scientist (Machine Intellection) I2R</td>\n",
       "      <td>A*STAR RESEARCH ENTITIES</td>\n",
       "      <td>Posted 27 Mar 2020</td>\n",
       "      <td>0</td>\n",
       "      <td>Professional</td>\n",
       "      <td>Sciences  Laboratory  R&amp;D</td>\n",
       "      <td>Developing enhancing automating and managing a...</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>Med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MCF-2020-0045289</td>\n",
       "      <td>Contract Permanent</td>\n",
       "      <td>Scientist (Machine Intellection) I2R</td>\n",
       "      <td>A*STAR RESEARCH ENTITIES</td>\n",
       "      <td>Posted 27 Mar 2020</td>\n",
       "      <td>0</td>\n",
       "      <td>Professional</td>\n",
       "      <td>Sciences  Laboratory  R&amp;D</td>\n",
       "      <td>Protein nodes discovering in cancer Biomarker ...</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>Med</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Job_Id            Emp_Type                             Job_Title  \\\n",
       "0  MCF-2020-0045240  Contract Permanent  Scientist (Machine Intellection) I2R   \n",
       "1  MCF-2020-0045289  Contract Permanent  Scientist (Machine Intellection) I2R   \n",
       "\n",
       "                    Company         Date_Posted Year_Experience     Seniority  \\\n",
       "0  A*STAR RESEARCH ENTITIES  Posted 27 Mar 2020               0  Professional   \n",
       "1  A*STAR RESEARCH ENTITIES  Posted 27 Mar 2020               0  Professional   \n",
       "\n",
       "                    Category  \\\n",
       "0  Sciences  Laboratory  R&D   \n",
       "1  Sciences  Laboratory  R&D   \n",
       "\n",
       "                                        Requirements  Min_Salary  Max_Salary  \\\n",
       "0  Developing enhancing automating and managing a...      4500.0      9000.0   \n",
       "1  Protein nodes discovering in cancer Biomarker ...      4500.0      9000.0   \n",
       "\n",
       "   Avg_Salary Salary_range  \n",
       "0      6750.0          Med  \n",
       "1      6750.0          Med  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean = clean_kie(df1)\n",
    "print(df_clean.shape)\n",
    "df_clean.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word count function\n",
    "def word_count(df_col):\n",
    "\n",
    "    str_counts = 0\n",
    "    sum_str = 0\n",
    "\n",
    "    for i in range (len(df_col)):    \n",
    "        str_counts = len(df_col[i].split())\n",
    "        sum_str = sum_str + str_counts\n",
    "\n",
    "    print(sum_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78351\n"
     ]
    }
   ],
   "source": [
    "#number of word found in Requirements column before clean\n",
    "word_count(df_clean['Requirements'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_words(word_count, features):\n",
    "\n",
    "    num_word = np.asarray(word_count.sum(axis=0)).reshape(-1)\n",
    "    most_count = num_word.argsort()[::-1]\n",
    "    key_word = pd.Series(num_word[most_count], \n",
    "                           index=features[most_count])\n",
    "\n",
    "    return key_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_word_fil(df):\n",
    "    \n",
    "    #stop words were added to filter some generic recurring business terms.\n",
    "    stop = stopwords.words('english')\n",
    "    stop += ['regret','shortlisted', 'candidates','notified','etc', 'take', 'hands','added','able','writting',\n",
    "             'year','years','least', 'related','using', 'and', 'ability','work','skills','advantage','written'\n",
    "            'develop','good','team','design','knowledge','experience','following','areas', 'ability','and','in','to']\n",
    "    \n",
    "    #most common words for requirements\n",
    "    cvt = CountVectorizer(lowercase=True, strip_accents='unicode',max_features=80000, min_df=1, max_df=0.9,\n",
    "                          stop_words=stop, ngram_range=(1,2))\n",
    "    vect_word = cvt.fit_transform(df['Requirements'])\n",
    "    features = np.array(cvt.get_feature_names()) \n",
    "\n",
    "    key_word = freq_words(vect_word, features)\n",
    "    \n",
    "    #update stop_word with common words\n",
    "    new_stop = key_word[key_word<5].index\n",
    "    stop.extend(new_stop)\n",
    "    \n",
    "    pat = r'\\b(?:{})\\b'.format('|'.join(stop))\n",
    "    df['Requirements'] = df['Requirements'].str.replace(pat, \" \")\n",
    "    df['Requirements'] = df['Requirements'].map(lambda x: x.strip())\n",
    "    df['Requirements'] = df['Requirements'].replace({' +':\" \"},regex=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39378\n"
     ]
    }
   ],
   "source": [
    "data_df = stop_word_fil(df_clean)\n",
    "\n",
    "#number of word found in Requirements column after clean\n",
    "word_count(data_df['Requirements'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save output file for KIE\n",
    "\n",
    "data_df.to_csv('{}JOB_DATA_v11.csv'.format(output_path), index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dummified Seniority columns to use as predictor features\n",
    "seniority_cat=data_df['Seniority'].str.get_dummies()\n",
    "salary_cat=data_df['Salary_range'].str.get_dummies()\n",
    "df = pd.concat([data_df, seniority_cat, salary_cat], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=0.7, max_features=1500, min_df=5,\n",
       "                ngram_range=(2, 3), preprocessor=None,\n",
       "                stop_words=['i', 'me', 'my', 'myself', 'we', 'our', 'ours',\n",
       "                            'ourselves', 'you', \"you're\", \"you've\", \"you'll\",\n",
       "                            \"you'd\", 'your', 'yours', 'yourself', 'yourselves',\n",
       "                            'he', 'him', 'his', 'himself', 'she', \"she's\",\n",
       "                            'her', 'hers', 'herself', 'it', \"it's\", 'its',\n",
       "                            'itself', ...],\n",
       "                strip_accents='unicode', token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CountVectorizer job requirements columns\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "cvec = CountVectorizer(lowercase=True, strip_accents='unicode',\n",
    "                       max_features=1500, min_df=5, max_df=0.7, \n",
    "                       stop_words=stop,ngram_range=(2,3))\n",
    "cvec.fit(df['Requirements'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Id</th>\n",
       "      <th>Emp_Type</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Date_Posted</th>\n",
       "      <th>Year_Experience</th>\n",
       "      <th>Seniority</th>\n",
       "      <th>Category</th>\n",
       "      <th>Requirements</th>\n",
       "      <th>Min_Salary</th>\n",
       "      <th>Max_Salary</th>\n",
       "      <th>Avg_Salary</th>\n",
       "      <th>Salary_range</th>\n",
       "      <th>Jr Executive</th>\n",
       "      <th>Management</th>\n",
       "      <th>Professional</th>\n",
       "      <th>Sr Executive</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Med</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MCF-2020-0045240</td>\n",
       "      <td>Contract Permanent</td>\n",
       "      <td>Scientist (Machine Intellection) I2R</td>\n",
       "      <td>A*STAR RESEARCH ENTITIES</td>\n",
       "      <td>Posted 27 Mar 2020</td>\n",
       "      <td>0</td>\n",
       "      <td>Professional</td>\n",
       "      <td>Sciences  Laboratory  R&amp;D</td>\n",
       "      <td>Developing models Creating visualizations effe...</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>Med</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Job_Id            Emp_Type                             Job_Title  \\\n",
       "0  MCF-2020-0045240  Contract Permanent  Scientist (Machine Intellection) I2R   \n",
       "\n",
       "                    Company         Date_Posted Year_Experience     Seniority  \\\n",
       "0  A*STAR RESEARCH ENTITIES  Posted 27 Mar 2020               0  Professional   \n",
       "\n",
       "                    Category  \\\n",
       "0  Sciences  Laboratory  R&D   \n",
       "\n",
       "                                        Requirements  Min_Salary  Max_Salary  \\\n",
       "0  Developing models Creating visualizations effe...      4500.0      9000.0   \n",
       "\n",
       "   Avg_Salary Salary_range  Jr Executive  Management  Professional  \\\n",
       "0      6750.0          Med             0           0             1   \n",
       "\n",
       "   Sr Executive  High  Low  Med  \n",
       "0             0     0    0    1  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating predictor and target dataset\n",
    "model_data = df.drop(columns=['Job_Title','Company','Seniority','Category','Min_Salary',\n",
    "                               'Max_Salary','Emp_Type','Avg_Salary', 'Job_Id', 'Date_Posted'])\n",
    "\n",
    "nlp = pd.DataFrame(cvec.transform(model_data['Requirements']).todense(),columns=cvec.get_feature_names())\n",
    "\n",
    "senior_nlp = pd.concat([model_data, nlp], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(453, 1508)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = senior_nlp.drop(columns=['Salary_range','Requirements'])\n",
    "X_nlp = nlp\n",
    "y = senior_nlp['Salary_range'].values\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data with dummified 'seniority' and countvectorized 'requirements'\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data with countvectorized 'requirements' only\n",
    "X_train_nlp, X_test_nlp, y_train_nlp, y_test_nlp = train_test_split(X_nlp, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier(max_depth=4, random_state=42)\n",
    "dtc = dtc.fit(X_train , y_train)\n",
    "\n",
    "dtc1 = DecisionTreeClassifier(max_depth=4, random_state=42)\n",
    "dtc_nlp = dtc1.fit(X_train_nlp , y_train_nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Low       1.00      1.00      1.00        40\n",
      "         Med       1.00      1.00      1.00        40\n",
      "        High       1.00      1.00      1.00        56\n",
      "\n",
      "    accuracy                           1.00       136\n",
      "   macro avg       1.00      1.00      1.00       136\n",
      "weighted avg       1.00      1.00      1.00       136\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,dtc.predict(X_test),target_names=[\"Low\", \"Med\", \"High\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred Low</th>\n",
       "      <th>Pred Med</th>\n",
       "      <th>Pred High</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Low</th>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Med</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual High</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Pred Low  Pred Med  Pred High\n",
       "Actual Low         40         0          0\n",
       "Actual Med          0        40          0\n",
       "Actual High         0         0         56"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(y_test,dtc.predict(X_test)),\n",
    "             index=['Actual Low','Actual Med', 'Actual High'],\n",
    "             columns=['Pred Low','Pred Med','Pred High'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Low       0.81      0.42      0.56        40\n",
      "         Med       0.53      0.20      0.29        40\n",
      "        High       0.47      0.84      0.60        56\n",
      "\n",
      "    accuracy                           0.53       136\n",
      "   macro avg       0.60      0.49      0.48       136\n",
      "weighted avg       0.59      0.53      0.50       136\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_nlp,dtc_nlp.predict(X_test_nlp),target_names=[\"Low\", \"Med\", \"High\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred Low</th>\n",
       "      <th>Pred Med</th>\n",
       "      <th>Pred High</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Low</th>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Med</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual High</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Pred Low  Pred Med  Pred High\n",
       "Actual Low         17         2         21\n",
       "Actual Med          0         8         32\n",
       "Actual High         4         5         47"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(y_test_nlp,dtc_nlp.predict(X_test_nlp)),\n",
    "             index=['Actual Low','Actual Med', 'Actual High'],\n",
    "             columns=['Pred Low','Pred Med','Pred High'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
